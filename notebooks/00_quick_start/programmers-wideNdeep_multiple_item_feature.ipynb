{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide and Deep Model\n",
    "\n",
    "<br>\n",
    "\n",
    "- [**Wide-and-deep**](https://arxiv.org/abs/1606.07792)\n",
    "- using TensorFlow high-level Estimator API (v1.12)\n",
    "- implementation of [MicroSoft Recommneders](https://github.com/microsoft/recommenders)\n",
    "- please see the source_code of [my version](https://github.com/mjmingd/recommenders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 1.13.1\n",
      "GPUs:\n",
      " []\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from reco_utils.common.constants import (\n",
    "    DEFAULT_USER_COL as USER_COL,\n",
    "    DEFAULT_ITEM_COL as ITEM_COL,\n",
    "    DEFAULT_RATING_COL as RATING_COL,\n",
    "    DEFAULT_PREDICTION_COL as PREDICT_COL,\n",
    "    SEED\n",
    ")\n",
    "from reco_utils.common import tf_utils, gpu_utils, plot\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.dataset.pandas_df_utils import user_item_pairs\n",
    "from reco_utils.dataset.python_splitters import python_random_split\n",
    "import reco_utils.evaluation.python_evaluation as evaluator\n",
    "import reco_utils.recommender.wide_deep.wide_deep_utils as wide_deep\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.VERSION)\n",
    "print(\"GPUs:\\n\", gpu_utils.get_gpu_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Metrics to use for evaluation\n",
    "RANKING_METRICS = []\n",
    "RATING_METRICS = []\n",
    "\n",
    "# Use session hook to evaluate model while training\n",
    "EVALUATE_WHILE_TRAINING = True\n",
    "\n",
    "# set your column name\n",
    "ITEM_COL = 'jobID'\n",
    "ITEM_FEAT_COL = 'tagID,companyID,companySize'\n",
    "ITEM_FEAT_FLAG = True\n",
    "RATING_COL = 'applied'\n",
    "# USER_FEAT_FLAG = True\n",
    "\n",
    "# Set seed for deterministic result\n",
    "RANDOM_SEED = 3737  \n",
    "\n",
    "# set directories\n",
    "DATA_DIR = '../../../train_job/'\n",
    "RESULT_DIR = '../../../result/'\n",
    "EXPORT_DIR_BASE = '../../output/'\n",
    "\n",
    "# Model checkpoints directory. If None, use temp-dir.\n",
    "MODEL_DIR = None\n",
    "\n",
    "#### Hyperparameters\n",
    "MODEL_TYPE = 'wide_deep'\n",
    "STEPS = 1000  # Number of batches to train\n",
    "BATCH_SIZE = 32 ##epcohs = steps * batch_size / train_data\n",
    "\n",
    "# Wide (linear) model hyperparameters\n",
    "LINEAR_OPTIMIZER = 'adagrad'\n",
    "LINEAR_OPTIMIZER_LR = 0.0621  # Learning rate\n",
    "LINEAR_L1_REG = 0.5           # Regularization rate for FtrlOptimizer\n",
    "LINEAR_L2_REG = 0.0\n",
    "LINEAR_MOMENTUM = 0.99         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# DNN model hyperparameters\n",
    "DNN_OPTIMIZER = 'adadelta'\n",
    "DNN_OPTIMIZER_LR = 0.005\n",
    "DNN_L1_REG = 0.5           # Regularization rate for FtrlOptimizer\n",
    "DNN_L2_REG = 0.0\n",
    "DNN_MOMENTUM = 0.99         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "# Layer dimensions. Defined as follows to make this notebook runnable from Hyperparameter tuning services like AzureML Hyperdrive\n",
    "DNN_HIDDEN_LAYER_1 = 128     # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_2 = 64    # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_3 = 8   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_4 = 256   # Note, at least one layer should have nodes.\n",
    "DNN_HIDDEN_UNITS = [h for h in [DNN_HIDDEN_LAYER_1, DNN_HIDDEN_LAYER_2, DNN_HIDDEN_LAYER_3, DNN_HIDDEN_LAYER_4] if h > 0]\n",
    "DNN_USER_DIM = 32          # User embedding feature dimension\n",
    "DNN_ITEM_DIM = 16          # Item embedding feature dimension\n",
    "DNN_DROPOUT = 0.8\n",
    "DNN_BATCH_NORM = 1         # 1 to use batch normalization, 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_DIR is None:\n",
    "    TMP_DIR = TemporaryDirectory()\n",
    "    model_dir = TMP_DIR.name\n",
    "else:\n",
    "    if os.path.exists(MODEL_DIR) and os.listdir(MODEL_DIR):\n",
    "        raise ValueError(\n",
    "            \"Model exists in {}. Use different directory name or \"\n",
    "            \"remove the existing checkpoint files first\".format(MODEL_DIR)\n",
    "        )\n",
    "    TMP_DIR = None\n",
    "    model_dir = MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "      <th>applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe292163d06253b716e9a0099b42031d</td>\n",
       "      <td>15de21c670ae7c3f6f3f1f37029303c9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6377fa90618fae77571e8dc90d98d409</td>\n",
       "      <td>55b37c5c270e5d84c793e486d798c01d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ec0888a5b04139be0dfe942c7eb4199</td>\n",
       "      <td>0fcbc61acd0479dc77e3cccc0f5ffca7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f862b39f767d3a1991bdeb2ea1401c9c</td>\n",
       "      <td>3b5dca501ee1e6d8cd7b905f4e1bf723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cac14930c65d72c16efac2c51a6b7f71</td>\n",
       "      <td>287e03db1d99e0ec2edb90d079e142f3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userID                             jobID  applied\n",
       "0  fe292163d06253b716e9a0099b42031d  15de21c670ae7c3f6f3f1f37029303c9        0\n",
       "1  6377fa90618fae77571e8dc90d98d409  55b37c5c270e5d84c793e486d798c01d        0\n",
       "2  8ec0888a5b04139be0dfe942c7eb4199  0fcbc61acd0479dc77e3cccc0f5ffca7        1\n",
       "3  f862b39f767d3a1991bdeb2ea1401c9c  3b5dca501ee1e6d8cd7b905f4e1bf723        0\n",
       "4  cac14930c65d72c16efac2c51a6b7f71  287e03db1d99e0ec2edb90d079e142f3        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(DATA_DIR + 'train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebaee1af0c501f22ddfe242fc16dae53</td>\n",
       "      <td>352407221afb776e3143e8a1a0577885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ab05403ac7808cbfba3da26665f7a9c</td>\n",
       "      <td>96b9bff013acedfb1d140579e2fbeb63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33349e909eba71677299d2fc97e158b7</td>\n",
       "      <td>58d4d1e7b1e97b258c9ed0b37e02d087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac985a9db5faeb44c94a334430ccc241</td>\n",
       "      <td>ccb0989662211f61edae2e26d58ea92f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d41e0e6f6f1e29098d9d152511503ab2</td>\n",
       "      <td>4a213d37242bdcad8e7300e202e7caa4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userID                             jobID\n",
       "0  ebaee1af0c501f22ddfe242fc16dae53  352407221afb776e3143e8a1a0577885\n",
       "1  9ab05403ac7808cbfba3da26665f7a9c  96b9bff013acedfb1d140579e2fbeb63\n",
       "2  33349e909eba71677299d2fc97e158b7  58d4d1e7b1e97b258c9ed0b37e02d087\n",
       "3  ac985a9db5faeb44c94a334430ccc241  ccb0989662211f61edae2e26d58ea92f\n",
       "4  d41e0e6f6f1e29098d9d152511503ab2  4a213d37242bdcad8e7300e202e7caa4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_DIR + 'test_job.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2435</td>\n",
       "      <td>2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>196</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>b052e2e0c0ad1b2d5036bd56e27d061c</td>\n",
       "      <td>da0d1111d2dc5d489242e60ebcbaf988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>49</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  userID                             jobID\n",
       "count                               2435                              2435\n",
       "unique                               196                               591\n",
       "top     b052e2e0c0ad1b2d5036bd56e27d061c  da0d1111d2dc5d489242e60ebcbaf988\n",
       "freq                                  49                                24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Load features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### job tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobID</th>\n",
       "      <th>tagID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320722549d1751cf3f247855f937b982</td>\n",
       "      <td>d38901788c533e8286cb6400b40b386d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e744f91c29ec99f0e662c9177946c627</td>\n",
       "      <td>3948ead63a9f2944218de038d8934305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              jobID                             tagID\n",
       "0  320722549d1751cf3f247855f937b982  d38901788c533e8286cb6400b40b386d\n",
       "1  e744f91c29ec99f0e662c9177946c627  3948ead63a9f2944218de038d8934305"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_tags_df = pd.read_csv(DATA_DIR + 'job_tags.csv')\n",
    "job_tags_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tagID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagID</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602d1305678a8d5fdb372271e980da6a</td>\n",
       "      <td>Amazon Web Services(AWS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e3251075554389fe91d17a794861d47b</td>\n",
       "      <td>Tensorflow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tagID                   keyword\n",
       "0  602d1305678a8d5fdb372271e980da6a  Amazon Web Services(AWS)\n",
       "1  e3251075554389fe91d17a794861d47b                Tensorflow"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = pd.read_csv(DATA_DIR + 'tags.csv')\n",
    "tags_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>companyID</th>\n",
       "      <th>jobID</th>\n",
       "      <th>companySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00411460f7c92d2124a67ea0f4cb5f85</td>\n",
       "      <td>e5f6ad6ce374177eef023bf5d0c018b6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1905aedab9bf2477edc068a355bba31a</td>\n",
       "      <td>185e65bc40581880c4f2c82958de8cfe</td>\n",
       "      <td>11-50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          companyID                             jobID  \\\n",
       "0  00411460f7c92d2124a67ea0f4cb5f85  e5f6ad6ce374177eef023bf5d0c018b6   \n",
       "1  1905aedab9bf2477edc068a355bba31a  185e65bc40581880c4f2c82958de8cfe   \n",
       "\n",
       "  companySize  \n",
       "0         NaN  \n",
       "1       11-50  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_df = pd.read_csv(DATA_DIR + 'job_companies.csv')\n",
    "companies_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df['companySize'].fillna(1, inplace = True) # NaN 값을 1로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def companies_resize(s) : # 구간값을 특정 값으로 fix\n",
    "    if s == 1 : return 1\n",
    "    elif s == '1-10' : return 10\n",
    "    elif s == '11-50' : return 50\n",
    "    elif s == '51-100' : return 100\n",
    "    elif s == '101-200' : return 200\n",
    "    elif s == '201-500' : return 500\n",
    "    elif s == '501-1000' : return 1000\n",
    "    else : return 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_df['companySize'] = companies_df['companySize'].apply(lambda s : companies_resize(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 start encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature = pd.DataFrame(job_tags_df['jobID'].unique(), columns=['jobID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['tagID'] = job_feature['jobID'].apply(lambda jid : \n",
    "                                    job_tags_df.loc[job_tags_df['jobID']== jid]['tagID'].to_string(index=False).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using total tagID\n",
    "tag_encoder = sklearn.preprocessing.MultiLabelBinarizer(classes=list(tags_df['tagID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['tagID'] = tag_encoder.fit_transform( job_feature['tagID'].apply(lambda s: s.split(\"\\n \"))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companyID'] = job_feature['jobID'].apply(lambda jid : \n",
    "                                                  companies_df.loc[companies_df['jobID']== jid]['companyID'].to_string(index=False).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyID_encoder = sklearn.preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companyID'] = companyID_encoder.fit_transform(job_feature['companyID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyID_OH = sklearn.preprocessing.OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companyID'] = companyID_OH.fit_transform(job_feature['companyID'].to_numpy().reshape(-1, 1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companySize'] = job_feature['jobID'].apply(lambda jid :\n",
    "                                                  companies_df.loc[companies_df['jobID']== jid]['companySize'].to_string(index=False).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "companySize_encoder = sklearn.preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companySize'] = companySize_encoder.fit_transform(job_feature['companySize'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "companySize_OH = sklearn.preprocessing.OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_feature['companySize'] = companySize_OH.fit_transform(job_feature['companySize'].to_numpy().reshape(-1, 1)).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_data, job_feature, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "      <th>applied</th>\n",
       "      <th>tagID</th>\n",
       "      <th>companyID</th>\n",
       "      <th>companySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe292163d06253b716e9a0099b42031d</td>\n",
       "      <td>15de21c670ae7c3f6f3f1f37029303c9</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6377fa90618fae77571e8dc90d98d409</td>\n",
       "      <td>55b37c5c270e5d84c793e486d798c01d</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ec0888a5b04139be0dfe942c7eb4199</td>\n",
       "      <td>0fcbc61acd0479dc77e3cccc0f5ffca7</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f862b39f767d3a1991bdeb2ea1401c9c</td>\n",
       "      <td>3b5dca501ee1e6d8cd7b905f4e1bf723</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cac14930c65d72c16efac2c51a6b7f71</td>\n",
       "      <td>287e03db1d99e0ec2edb90d079e142f3</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userID                             jobID  \\\n",
       "0  fe292163d06253b716e9a0099b42031d  15de21c670ae7c3f6f3f1f37029303c9   \n",
       "1  6377fa90618fae77571e8dc90d98d409  55b37c5c270e5d84c793e486d798c01d   \n",
       "2  8ec0888a5b04139be0dfe942c7eb4199  0fcbc61acd0479dc77e3cccc0f5ffca7   \n",
       "3  f862b39f767d3a1991bdeb2ea1401c9c  3b5dca501ee1e6d8cd7b905f4e1bf723   \n",
       "4  cac14930c65d72c16efac2c51a6b7f71  287e03db1d99e0ec2edb90d079e142f3   \n",
       "\n",
       "   applied                                              tagID  \\\n",
       "0        0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1        0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2        1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3        0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4        0  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           companyID  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                companySize  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]  \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "4  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.merge(test_data, job_feature, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "      <th>tagID</th>\n",
       "      <th>companyID</th>\n",
       "      <th>companySize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebaee1af0c501f22ddfe242fc16dae53</td>\n",
       "      <td>352407221afb776e3143e8a1a0577885</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ab05403ac7808cbfba3da26665f7a9c</td>\n",
       "      <td>96b9bff013acedfb1d140579e2fbeb63</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33349e909eba71677299d2fc97e158b7</td>\n",
       "      <td>58d4d1e7b1e97b258c9ed0b37e02d087</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac985a9db5faeb44c94a334430ccc241</td>\n",
       "      <td>ccb0989662211f61edae2e26d58ea92f</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d41e0e6f6f1e29098d9d152511503ab2</td>\n",
       "      <td>4a213d37242bdcad8e7300e202e7caa4</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userID                             jobID  \\\n",
       "0  ebaee1af0c501f22ddfe242fc16dae53  352407221afb776e3143e8a1a0577885   \n",
       "1  9ab05403ac7808cbfba3da26665f7a9c  96b9bff013acedfb1d140579e2fbeb63   \n",
       "2  33349e909eba71677299d2fc97e158b7  58d4d1e7b1e97b258c9ed0b37e02d087   \n",
       "3  ac985a9db5faeb44c94a334430ccc241  ccb0989662211f61edae2e26d58ea92f   \n",
       "4  d41e0e6f6f1e29098d9d152511503ab2  4a213d37242bdcad8e7300e202e7caa4   \n",
       "\n",
       "                                               tagID  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           companyID  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                companySize  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5994 train samples and 6 test samples\n"
     ]
    }
   ],
   "source": [
    "train, valid = python_random_split(train_data, ratio=0.999, seed=RANDOM_SEED)\n",
    "\n",
    "print(\"{} train samples and {} test samples\".format(len(train), len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 708 items and 196 users in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Unique items in the dataset\n",
    "if ITEM_FEAT_COL is None:\n",
    "    items = train_data.drop_duplicates(ITEM_COL)[[ITEM_COL]].reset_index(drop=True)\n",
    "    item_feat_shape = None\n",
    "else:\n",
    "    if not ITEM_FEAT_FLAG :\n",
    "        items = train_data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "        item_feat_shape = len(items[ITEM_FEAT_COL][0])\n",
    "    else :\n",
    "        ITEM_FEAT_COL_LIST = ITEM_FEAT_COL.split(',')\n",
    "        items = train_data.drop_duplicates(ITEM_COL)[[ITEM_COL] + ITEM_FEAT_COL_LIST].reset_index(drop=True)\n",
    "        item_feat_shape = [len(items[col][0]) for col in ITEM_FEAT_COL_LIST]\n",
    "        \n",
    "# Unique users in the dataset\n",
    "users = train_data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "print(\"Total {} items and {} users in the dataset\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model checkpoint every n steps.\n",
    "save_checkpoints_steps = max(1, STEPS // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide feature specs:\n",
      "\t VocabularyListCategoricalColumn(key='userID', vocabulary_list=('fe292163d06253b716e9a0099b42031d', ' ...\n",
      "\t VocabularyListCategoricalColumn(key='jobID', vocabulary_list=('15de21c670ae7c3f6f3f1f37029303c9', '5 ...\n",
      "\t CrossedColumn(keys=(VocabularyListCategoricalColumn(key='userID', vocabulary_list=('fe292163d06253b7 ...\n",
      "Deep feature specs:\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='userID', vocabulary_list=('f ...\n",
      "\t EmbeddingColumn(categorical_column=VocabularyListCategoricalColumn(key='jobID', vocabulary_list=('15 ...\n",
      "\t NumericColumn(key='tagID', shape=(887,), default_value=None, dtype=tf.float32, normalizer_fn=None) ...\n",
      "\t NumericColumn(key='companyID', shape=(276,), default_value=None, dtype=tf.float32, normalizer_fn=Non ...\n",
      "\t NumericColumn(key='companySize', shape=(8,), default_value=None, dtype=tf.float32, normalizer_fn=Non ...\n"
     ]
    }
   ],
   "source": [
    "# Define wide (linear) and deep (dnn) features\n",
    "wide_columns, deep_columns = wide_deep.build_feature_columns(\n",
    "    users=users[USER_COL].values,\n",
    "    items=items[ITEM_COL].values,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    item_feat_col=ITEM_FEAT_COL,\n",
    "    crossed_feat_dim=1000,\n",
    "    user_dim=DNN_USER_DIM,\n",
    "    item_dim=DNN_ITEM_DIM,\n",
    "    item_feat_shape=item_feat_shape,\n",
    "    model_type=MODEL_TYPE,\n",
    "    item_feat_flag=ITEM_FEAT_FLAG\n",
    ")\n",
    "\n",
    "print(\"Wide feature specs:\")\n",
    "for c in wide_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")\n",
    "print(\"Deep feature specs:\")\n",
    "for c in deep_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah', '_tf_random_seed': 3737, '_save_summary_steps': 100, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1338e9470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a model based on the parameters\n",
    "model = wide_deep.build_model(\n",
    "    model_dir=model_dir,\n",
    "    wide_columns=wide_columns,\n",
    "    deep_columns=deep_columns,\n",
    "    linear_optimizer=tf_utils.build_optimizer(LINEAR_OPTIMIZER, LINEAR_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': LINEAR_L1_REG,\n",
    "        'l2_regularization_strength': LINEAR_L2_REG,\n",
    "        'momentum': LINEAR_MOMENTUM,\n",
    "    }),\n",
    "    dnn_optimizer=tf_utils.build_optimizer(DNN_OPTIMIZER, DNN_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': DNN_L1_REG,\n",
    "        'l2_regularization_strength': DNN_L2_REG,\n",
    "        'momentum': DNN_MOMENTUM,  \n",
    "    }),\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "    dnn_dropout=DNN_DROPOUT,\n",
    "    dnn_batch_norm=(DNN_BATCH_NORM==1),\n",
    "    log_every_n_iter=max(1, STEPS//10),  # log 10 times\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedClassifier at 0x1338e9a20>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': PREDICT_COL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define training hooks to track performance while training\n",
    "hooks = []\n",
    "if EVALUATE_WHILE_TRAINING:\n",
    "    evaluation_logger = tf_utils.MetricsLogger()\n",
    "    for metrics in (RANKING_METRICS, RATING_METRICS):\n",
    "        if len(metrics) > 0:\n",
    "            hooks.append(\n",
    "                tf_utils.evaluation_log_hook(\n",
    "                    model,\n",
    "                    logger=evaluation_logger,\n",
    "                    true_df=valid,\n",
    "                    y_col=RATING_COL,\n",
    "                    eval_df=ranking_pool if metrics==RANKING_METRICS else valid,\n",
    "                    every_n_iter=save_checkpoints_steps,\n",
    "                    model_dir=model_dir,\n",
    "                    eval_fns=[evaluator.metrics[m] for m in metrics],\n",
    "                    **({**cols, 'k': TOP_K} if metrics==RANKING_METRICS else cols)\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Define training input (sample feeding) function\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=train,\n",
    "    y_col=RATING_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training steps = 1000, Batch size = 32 (num epochs = 5)\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2997: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/ops/lookup_ops.py:1137: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "INFO:tensorflow:loss = 26.35226, step = 1\n",
      "INFO:tensorflow:global_step/sec: 40.5026\n",
      "INFO:tensorflow:loss = 17.212816, step = 101 (2.469 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 61.4444\n",
      "INFO:tensorflow:loss = 18.080254, step = 201 (1.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.575\n",
      "INFO:tensorflow:loss = 10.981482, step = 301 (0.785 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 67.0184\n",
      "INFO:tensorflow:loss = 12.083433, step = 401 (1.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.869\n",
      "INFO:tensorflow:loss = 11.118322, step = 501 (0.648 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 58.9746\n",
      "INFO:tensorflow:loss = 10.094628, step = 601 (1.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.191\n",
      "INFO:tensorflow:loss = 22.42065, step = 701 (0.729 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 62.8323\n",
      "INFO:tensorflow:loss = 13.5600195, step = 801 (1.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.434\n",
      "INFO:tensorflow:loss = 20.90012, step = 901 (0.753 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 8.459732.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Training steps = {}, Batch size = {} (num epochs = {})\"\n",
    "    .format(STEPS, BATCH_SIZE, (STEPS*BATCH_SIZE)//len(train))\n",
    ")\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "try:\n",
    "    model.train(\n",
    "        input_fn=train_fn,\n",
    "        hooks=hooks,\n",
    "        steps=STEPS\n",
    "    )\n",
    "except tf.train.NanLossDuringTrainingError:\n",
    "    import warnings\n",
    "    warnings.warn(\n",
    "        \"Training stopped with NanLossDuringTrainingError. \"\n",
    "        \"Try other optimizers, smaller batch size and/or smaller learning rate.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_q/czkytp194_s6kb2464zr1n980000gn/T/tmp9qxkpeah/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test_data)))\n",
    "prediction_df = test_data.copy()\n",
    "prediction_df['applied'] = [p['class_ids'][0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>jobID</th>\n",
       "      <th>tagID</th>\n",
       "      <th>companyID</th>\n",
       "      <th>companySize</th>\n",
       "      <th>applied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebaee1af0c501f22ddfe242fc16dae53</td>\n",
       "      <td>352407221afb776e3143e8a1a0577885</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ab05403ac7808cbfba3da26665f7a9c</td>\n",
       "      <td>96b9bff013acedfb1d140579e2fbeb63</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33349e909eba71677299d2fc97e158b7</td>\n",
       "      <td>58d4d1e7b1e97b258c9ed0b37e02d087</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ac985a9db5faeb44c94a334430ccc241</td>\n",
       "      <td>ccb0989662211f61edae2e26d58ea92f</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d41e0e6f6f1e29098d9d152511503ab2</td>\n",
       "      <td>4a213d37242bdcad8e7300e202e7caa4</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             userID                             jobID  \\\n",
       "0  ebaee1af0c501f22ddfe242fc16dae53  352407221afb776e3143e8a1a0577885   \n",
       "1  9ab05403ac7808cbfba3da26665f7a9c  96b9bff013acedfb1d140579e2fbeb63   \n",
       "2  33349e909eba71677299d2fc97e158b7  58d4d1e7b1e97b258c9ed0b37e02d087   \n",
       "3  ac985a9db5faeb44c94a334430ccc241  ccb0989662211f61edae2e26d58ea92f   \n",
       "4  d41e0e6f6f1e29098d9d152511503ab2  4a213d37242bdcad8e7300e202e7caa4   \n",
       "\n",
       "                                               tagID  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           companyID  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                companySize  applied  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]        0  \n",
       "1  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]        0  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]        0  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]        0  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = prediction_df['applied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.loc[res==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MingD/PycharmProjects/untitled/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "res.to_csv(RESULT_DIR+'wideNdeep_multi_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
